# @package _global_

# example hyperparameter optimization of some experiment with Optuna:
# python train.py -m hparams_search=mnist_optuna experiment=example

defaults:
  - base
  - override /datamodule: electricity
  - override /model: electricity_elastic_net

model_type: "global"

model:
  lags_future_covariates:
    _target_: builtins.tuple
    _args_:
      - - ${model.lags}
        - ${model.output_chunk_length}

# here we define Optuna hyperparameter search
# it optimizes for value returned from function with @hydra.main decorator
# docs: https://hydra.cc/docs/next/plugins/optuna_sweeper
hydra:
  sweeper:
    # name of the study to persist optimization results
    study_name: "electricity-elastic-net-global"
    # define hyperparameter search space
    params:
      ++model.lags: range(2, 96, 2) # between 2 hours and 48 hours, with 1 hour increments
      ++model.output_chunk_length: choice(1, 6, 12, 24)
      ++model.model.l1_ratio: interval(0.0, 1.0)
