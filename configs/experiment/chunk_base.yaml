# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /ensemble: default.yaml
  - override /datamodule: electricity
  - override /lr_tuner: none
  - _self_
  - override /model: ${datamodule}_tcn # last for possible retrain override

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags:
  - ${hydra:runtime.choices.datamodule}
  - ${hydra:runtime.choices.model}

seed: 12345

chunk_idx_start: 0
chunk_idx_end: ${eval:'${datamodule.dataset_length} // ${datamodule.chunk_length}'}

# Scale the global model's parameters according to the number of models in the corresponding ensemble
scale_model_parameters: False

callbacks:
  early_stopping:
    patience: 10

trainer:
  max_epochs: 1000

# TODO: perhaps remove this from here? Maybe even import chunk_eval but before in the order so we can overwrite with this file
eval:
  kwargs:
    forecast_horizon: 24
    stride: 24
    retrain: False
    start: null # do not start evaluation from lookback_data_length when training models

logger:
  mlflow:
    experiment_name: ${mlflow-exp-name:'${hydra:runtime.choices.datamodule}-${hydra:runtime.choices.model}'}

plot_datasets: False

ensemble:
  fit_weights_every: 1
  lookback_data_length: 150
  autoregressive_mix: false # quick benchmarks reveal small differences in metrics, but performance is better with false
