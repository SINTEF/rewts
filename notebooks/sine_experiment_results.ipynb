{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pyrootutils\n",
    "\n",
    "root = pyrootutils.setup_root(\n",
    "    search_from=os.getcwd(),\n",
    "    indicator=[\".git\", \"pyproject.toml\"],\n",
    "    pythonpath=True,\n",
    "    dotenv=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import ast\n",
    "import glob\n",
    "import pickle\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# %matplotlib notebook\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import src.utils.plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Inspect Sine Experiment Results\n",
    "This notebook aids in inspecting the results of the sine experiments, and in collecting the necessary information for the paper: gathering the figures and outputting latex table data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "search_tags = None\n",
    "search_experiment_name = \"sine-eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: this notebook uses slow file-based search. Update to use mlflow-search as used in the other notebooks\n",
    "\n",
    "\n",
    "def extract_model_name(path):\n",
    "    # Define a regex pattern to capture the date-time segment and a potential subsequent segment\n",
    "    pattern = r\"(\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}-\\d{2})(?:\\/(\\d+))?\"\n",
    "\n",
    "    # Search the path for the pattern\n",
    "    match = re.search(pattern, path)\n",
    "\n",
    "    # If a match is found, construct the segment accordingly\n",
    "    if match:\n",
    "        date_time_part = match.group(1)\n",
    "\n",
    "        # If the subsequent segment exists\n",
    "        if match.group(2):\n",
    "            return f\"Global: {date_time_part}/{match.group(2)}\"\n",
    "        return f\"ReWTS: {date_time_part}\"\n",
    "\n",
    "    # If no match is found, return an empty string or handle accordingly\n",
    "    return None\n",
    "\n",
    "\n",
    "matched_runs = []\n",
    "model_names = []\n",
    "\n",
    "if search_experiment_name is not None:\n",
    "    for filename in glob.iglob(\n",
    "        str(root) + \"/logs/eval/multiruns/2023-09-06_18*/**/.hydra/config.yaml\", recursive=True\n",
    "    ):\n",
    "        match = False\n",
    "        config = OmegaConf.load(filename)\n",
    "        if (\n",
    "            search_experiment_name is not None\n",
    "            and config.get(\"logger\", {}).get(\"mlflow\", {}).get(\"experiment_name\", \"\")\n",
    "            == search_experiment_name\n",
    "        ):\n",
    "            match = True\n",
    "        elif search_tags is not None:\n",
    "            with open(os.path.join(filename, os.pardir, os.pardir, \"tags.log\"), \"r\") as tag_file:\n",
    "                file_tags = ast.literal_eval(tag_file.readlines()[0])\n",
    "            if not set(search_tags).isdisjoint(file_tags):\n",
    "                match = True\n",
    "        if not match:\n",
    "            continue\n",
    "        run_dir = os.path.normpath(os.path.join(filename, os.pardir, os.pardir))\n",
    "        model_name = extract_model_name(config[\"model_dir\"])\n",
    "        eval_results = OmegaConf.load(os.path.join(run_dir, \"eval_test_results.yaml\"))\n",
    "        matched_runs.append(\n",
    "            dict(\n",
    "                dataset_name=config[\"datamodule\"][\"dataset_name\"],\n",
    "                chunk_idx=config[\"datamodule\"].get(\"chunk_idx\", None),\n",
    "                metrics=eval_results[\"metrics\"],\n",
    "                model_name=model_name,\n",
    "                run_path=run_dir,\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(f\"found {len(matched_runs)} runs matching searched terms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(matched_runs)\n",
    "df = pd.concat([df.drop(\"metrics\", axis=1), df[\"metrics\"].apply(pd.Series)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "notation = \"%.2E\"\n",
    "base = 1\n",
    "dataset_order = [\"sine-train\", \"sine-test\"]\n",
    "\n",
    "# Filter out non-integer chunk_idx values\n",
    "latex_df = df[df[\"chunk_idx\"].apply(lambda x: isinstance(x, int))]\n",
    "\n",
    "latex_df = latex_df.copy()\n",
    "# Modify the model_name column\n",
    "latex_df[\"model_name\"] = latex_df[\"model_name\"].apply(lambda name: name.split(\":\")[0])\n",
    "\n",
    "# Pivot the dataframe to create a wide format\n",
    "latex_df = latex_df.pivot_table(\n",
    "    index=[\"dataset_name\", \"model_name\"], columns=\"chunk_idx\", values=\"test_mse\", aggfunc=\"mean\"\n",
    ").reset_index()\n",
    "\n",
    "# Reorder so that 'train' dataset comes first\n",
    "latex_df = latex_df.sort_values(\n",
    "    by=\"dataset_name\",\n",
    "    key=lambda column: column.map({name: i for i, name in enumerate(dataset_order)}),\n",
    ")\n",
    "\n",
    "# Calculate the average metric over chunks\n",
    "latex_df[\"avg\"] = latex_df.iloc[:, 2:].mean(axis=1)\n",
    "\n",
    "# Calculate the average metric over chunks\n",
    "latex_df.iloc[:, 2:] = latex_df.iloc[:, 2:] / base\n",
    "\n",
    "# Convert the dataframe to LaTeX format\n",
    "latex_output = latex_df.to_latex(index=False, float_format=notation)\n",
    "\n",
    "print(latex_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_configs = {}\n",
    "for run in matched_runs:\n",
    "    if run[\"dataset_name\"] not in dataset_configs:\n",
    "        dataset_configs[run[\"dataset_name\"]] = OmegaConf.load(\n",
    "            os.path.join(run[\"run_path\"], \".hydra\", \"config.yaml\")\n",
    "        )[\"datamodule\"]\n",
    "\n",
    "for dataset_name, dataset_config in dataset_configs.items():\n",
    "    # Extract amplitude and frequency values\n",
    "    amplitude_vals = [str(chunk[\"amplitude\"]) for chunk in dataset_config[\"data_args\"]]\n",
    "    frequency_vals = [str(chunk[\"frequency\"]) for chunk in dataset_config[\"data_args\"]]\n",
    "\n",
    "    # Create the amplitude and frequency rows\n",
    "    amplitude_row = (\n",
    "        f\"{dataset_name} & Amplitude $A$ & \"\n",
    "        + \" & \".join([str(a) for a in amplitude_vals])\n",
    "        + \" \\\\\\\\\"\n",
    "    )\n",
    "    frequency_row = (\n",
    "        f\"{dataset_name} & Frequency $\\\\omega$ & \"\n",
    "        + \" & \".join([str(f) for f in frequency_vals])\n",
    "        + \" \\\\\\\\\"\n",
    "    )\n",
    "\n",
    "    print(amplitude_row)\n",
    "    print(frequency_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def set_matplotlib_attributes(font_size=8, font=\"DejaVu Sans\"):\n",
    "    sns.set_theme(\n",
    "        style=\"white\",\n",
    "        rc={\n",
    "            \"font.size\": font_size,\n",
    "            \"font.family\": font,\n",
    "            \"axes.spines.right\": False,\n",
    "            \"axes.spines.top\": False,\n",
    "        },\n",
    "        font_scale=1,\n",
    "    )\n",
    "    # matplotlib.rcParams.update({'font.size': font_size, 'font.family': font})\n",
    "\n",
    "\n",
    "def set_figure_size(fig, column_span, height=None):\n",
    "    if height is None:\n",
    "        height = 4 if column_span == \"double\" else 6\n",
    "\n",
    "    cm = 1 / 2.54\n",
    "    if column_span == \"single\":\n",
    "        fig_width = 8.4 * cm\n",
    "    elif column_span == \"double\":\n",
    "        fig_width = 17.4 * cm\n",
    "    else:\n",
    "        raise ValueError()\n",
    "    figsize = (fig_width, height * cm)\n",
    "\n",
    "    fig.set_size_inches(*figsize)\n",
    "\n",
    "\n",
    "def plot_concatenated(_fig, _ax, p_data, preds, fontsize=8):\n",
    "    color_cycle = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "    plt.sca(_ax)\n",
    "\n",
    "    _ax.plot(p_data[\"series\"].time_index, np.squeeze(p_data[\"series\"].all_values()))\n",
    "\n",
    "    for p_i, p in enumerate(preds):\n",
    "        _ax.plot(\n",
    "            p.time_index,\n",
    "            np.squeeze(p.all_values()),\n",
    "            color=color_cycle[1 + p_i % (len(color_cycle) - 1)],\n",
    "        )\n",
    "\n",
    "    plt.grid(which=\"major\", axis=\"x\")\n",
    "    plt.xlabel(\"Chunk #\", fontsize=fontsize, fontweight=\"normal\")\n",
    "    xticks, _ = plt.xticks()\n",
    "    plt.xticks(ticks=xticks, labels=[f\"{(i) / (500) + 1:.0f}\" for i in xticks], fontsize=fontsize)\n",
    "    plt.yticks(fontsize=fontsize)\n",
    "    # for xtick in xticks[1:-2]:\n",
    "    #    plt.axvline(xtick, linestyle=\"dashed\")\n",
    "    plt.xlim(p_data[\"series\"].time_index[0], p_data[\"series\"].time_index[-1])\n",
    "\n",
    "    return _fig, _ax\n",
    "\n",
    "\n",
    "def save_figure(fig, path):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    fig.savefig(path + \".pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "    fig.savefig(path + \".png\", format=\"png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"ensemble\"\n",
    "dataset = \"test\"\n",
    "\n",
    "prediction_dirs = dict(\n",
    "    full=dict(\n",
    "        train=\"../path/to/global/train/eval/predictions\",\n",
    "        test=\"../path/to/global/test/eval/predictions\",\n",
    "    ),\n",
    "    ensemble=dict(\n",
    "        train=\"../path/to/ensemble/train/eval/predictions\",\n",
    "        test=\"../path/to/global/test/eval/predictions\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "prediction_dir = prediction_dirs[model_name][dataset]\n",
    "\n",
    "with open(os.path.join(prediction_dir, \"predictions.pkl\"), \"rb\") as f:\n",
    "    predictions = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(prediction_dir, \"data.pkl\"), \"rb\") as f:\n",
    "    prediction_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Concatenated Chunk Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fontsize = 8\n",
    "set_matplotlib_attributes(font_size=fontsize)\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "column_span = \"double\"\n",
    "set_figure_size(fig, column_span)\n",
    "\n",
    "fig, ax = plot_concatenated(fig, ax, prediction_data, predictions)\n",
    "save_figure(\n",
    "    fig,\n",
    "    os.path.join(\n",
    "        prediction_dir, \"..\", \"plots\", f\"sine_concat_{dataset}_{model_name}_{column_span}_column\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Edge effects plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fontsize = 8\n",
    "set_matplotlib_attributes(font_size=fontsize)\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "column_span = \"single\"\n",
    "set_figure_size(fig, column_span)\n",
    "\n",
    "color_cycle = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "time_slice = [850, 1150]\n",
    "\n",
    "ax.plot(\n",
    "    prediction_data[\"series\"].time_index[time_slice[0] : time_slice[1]],\n",
    "    np.squeeze(prediction_data[\"series\"].all_values()[time_slice[0] : time_slice[1]]),\n",
    ")\n",
    "\n",
    "for p_i, p in enumerate(predictions):\n",
    "    if p.start_time() >= time_slice[0] and p.start_time() < time_slice[-1]:\n",
    "        if p.end_time() > time_slice[-1]:\n",
    "            p, _ = p.split_after(time_slice[-1])\n",
    "        ax.plot(\n",
    "            p.time_index,\n",
    "            np.squeeze(p.all_values()),\n",
    "            color=color_cycle[1 + p_i % (len(color_cycle) - 1)],\n",
    "        )\n",
    "\n",
    "plt.grid(visible=False)\n",
    "plt.xlabel(\"Chunk #\", fontsize=fontsize, fontweight=\"normal\")\n",
    "# xticks, _ = plt.xticks()\n",
    "xticks = [time_slice[0], sum(time_slice) // 2]\n",
    "plt.xticks(\n",
    "    ticks=xticks,\n",
    "    labels=[f\"{i // (500) + 1:.0f}\" for i in xticks],\n",
    "    fontsize=fontsize,\n",
    "    fontweight=\"normal\",\n",
    ")\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.xlim(*time_slice)\n",
    "save_figure(\n",
    "    fig,\n",
    "    os.path.join(prediction_dir, \"..\", \"plots\", f\"sine_edge_{model_name}_{column_span}_column\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Concatenated with Ensemble Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert model_name == \"ensemble\"\n",
    "\n",
    "ensemble_weights = np.load(os.path.join(prediction_dir, \"..\", \"eval_test_weights.npy\"))\n",
    "\n",
    "fontsize = 8\n",
    "set_matplotlib_attributes(font_size=fontsize)\n",
    "fig, ax = plt.subplots(2, 1, sharex=False)\n",
    "column_span = \"double\"\n",
    "set_figure_size(fig, column_span, height=10)\n",
    "\n",
    "fig, ax[0] = plot_concatenated(fig, ax[0], prediction_data, predictions)\n",
    "# ax[0].set_xlabel(\"\")\n",
    "\n",
    "fig = src.utils.plotting.plot_ensemble_weights(\n",
    "    ensemble_weights, ax[1], time_indices=[160 + 30 * i for i in range(127)]\n",
    ")\n",
    "\n",
    "plt.sca(ax[1])\n",
    "ax[1].set_ylabel(\"Model Weights\", fontsize=fontsize, fontweight=\"normal\")\n",
    "ax[1].set_xlabel(\"\", fontsize=fontsize, fontweight=\"normal\")\n",
    "plt.xticks(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "\n",
    "plt.xticks(ticks=[], labels=[], fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "\n",
    "plt.grid(visible=False)\n",
    "plt.xlim(prediction_data[\"series\"].time_index[0], prediction_data[\"series\"].time_index[-1])\n",
    "\n",
    "pos = fig.axes[1].get_position()\n",
    "fig.axes[1].set_position([pos.bounds[0], pos.bounds[1] - 0.035, pos.bounds[2], pos.bounds[3]])\n",
    "\n",
    "# update position of colorbar\n",
    "pos = fig.axes[-1].get_position()\n",
    "fig.axes[-1].set_position([pos.bounds[0], pos.bounds[1] - 0.035, pos.bounds[2], pos.bounds[3]])\n",
    "plt.sca(fig.axes[-1])\n",
    "plt.xlabel(\"Model indices\", fontweight=\"normal\", fontsize=fontsize)\n",
    "plt.xticks(fontsize=fontsize, fontweight=\"normal\")\n",
    "\n",
    "\n",
    "save_figure(\n",
    "    fig,\n",
    "    os.path.join(\n",
    "        prediction_dir,\n",
    "        \"..\",\n",
    "        \"plots\",\n",
    "        f\"sine_concat_ensemble_weights_{dataset}_{column_span}_column\",\n",
    "    ),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
